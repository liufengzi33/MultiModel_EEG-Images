import torch
import torch.nn as nn
import os
from utils.model_loader import ModelLoader


class MultiModalFusionNetwork(nn.Module):
    def __init__(self,
                 eeg_model_name="EEGNet",
                 image_model_name="PlacesNet",
                 image_model_type="rsscnn",  # "rsscnn" æˆ– "sscnn"
                 in_chans=64,
                 n_classes=2,
                 input_window_samples=2000,
                 use_pretrained_eeg=True,
                 use_pretrained_image=True,
                 base_path="outputs",
                 fusion_dim=512,
                 dropout_rate=0.5,
                 fusion_method="concatenate"):
        """
        å¤šæ¨¡æ€èåˆç½‘ç»œ

        Args:
            eeg_model_name: EEGæ¨¡å‹åç§° ("EEGNet" æˆ– "ShallowFBCSPNet")
            image_model_name: å›¾åƒåŸºç¡€æ¨¡å‹åç§° ("AlexNet", "VGG", æˆ– "PlacesNet")
            image_model_type: å›¾åƒæ¨¡å‹ç±»å‹ ("rsscnn" æˆ– "sscnn")
            in_chans: EEGè¾“å…¥é€šé“æ•°
            n_classes: åˆ†ç±»ç±»åˆ«æ•°
            input_window_samples: EEGè¾“å…¥æ—¶é—´ç‚¹æ•°
            use_pretrained_eeg: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒçš„EEGæ¨¡å‹
            use_pretrained_image: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒçš„å›¾åƒæ¨¡å‹
            base_path: æ¨¡å‹ä¿å­˜çš„åŸºç¡€è·¯å¾„
            fusion_dim: èåˆç‰¹å¾ç»´åº¦
            dropout_rate: dropoutç‡
            fusion_method: èåˆæ–¹æ³• ("concatenate", "add", "weighted")
        """
        super(MultiModalFusionNetwork, self).__init__()

        # åˆå§‹åŒ–æ¨¡å‹åŠ è½½å™¨
        self.model_loader = ModelLoader(base_path)

        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        pretrained_ssbcinet = None
        pretrained_image_model = None

        if use_pretrained_eeg:
            pretrained_ssbcinet = self.model_loader.load_eeg_model(
                model_name=eeg_model_name,
                in_chans=in_chans,
                n_classes=n_classes,
                input_window_samples=input_window_samples
            )

        if use_pretrained_image:
            pretrained_image_model = self.model_loader.load_image_model(
                model_type=image_model_type,
                base_model_name=image_model_name
            )

        # åˆå§‹åŒ–EEGç‰¹å¾æå–é€šè·¯
        self.eeg_feature_net = self._build_eeg_path(
            eeg_model_name=eeg_model_name,
            in_chans=in_chans,
            n_classes=n_classes,
            input_window_samples=input_window_samples,
            pretrained_ssbcinet=pretrained_ssbcinet
        )

        # åˆå§‹åŒ–å›¾åƒç‰¹å¾æå–é€šè·¯
        self.image_feature_net = self._build_image_path(
            image_model_name=image_model_name,
            pretrained_image_model=pretrained_image_model,
            image_model_type=image_model_type
        )

        # ç‰¹å¾æŠ•å½±å±‚
        self.eeg_projection = nn.Sequential(
            nn.Linear(self.eeg_feature_net.out_dim, fusion_dim),
            nn.ReLU(),
            nn.Dropout(dropout_rate)
        )

        self.image_projection = nn.Sequential(
            nn.Linear(self.image_feature_net.out_dim, fusion_dim),
            nn.ReLU(),
            nn.Dropout(dropout_rate)
        )

        # å¤šæ¨¡æ€èåˆé…ç½®
        self.fusion_method = fusion_method

        if self.fusion_method == "concatenate":
            fusion_input_dim = fusion_dim * 2
        elif self.fusion_method == "add":
            fusion_input_dim = fusion_dim
        elif self.fusion_method == "weighted":
            self.attention_fusion = CrossModalAttention(fusion_dim)
            fusion_input_dim = fusion_dim
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„èåˆæ–¹æ³•: {fusion_method}")

        # åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Linear(fusion_input_dim, 256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(dropout_rate / 2),
            nn.Linear(128, n_classes if n_classes > 2 else 1)
        )

        # åˆå§‹åŒ–æƒé‡ï¼ˆåªåˆå§‹åŒ–æ–°æ·»åŠ çš„å±‚ï¼‰
        self._initialize_weights()

    def _build_eeg_path(self, eeg_model_name, in_chans, n_classes, input_window_samples, pretrained_ssbcinet):
        """æ„å»ºEEGç‰¹å¾æå–é€šè·¯"""
        from eeg_models import EEGFeatureExtractor, EEGFusionNetwork

        class EEGFeaturePath(nn.Module):
            def __init__(self, feature_extractor, fusion_net, out_dim):
                super(EEGFeaturePath, self).__init__()
                self.feature_extractor = feature_extractor
                self.fusion = fusion_net
                self.out_dim = out_dim

            def forward(self, x1, x2):
                f1 = self.feature_extractor(x1)
                f2 = self.feature_extractor(x2)
                fused = self.fusion(f1, f2)
                return fused

        if pretrained_ssbcinet is not None:
            # ä½¿ç”¨é¢„è®­ç»ƒçš„SSBCINet
            print("âœ… ä½¿ç”¨é¢„è®­ç»ƒçš„SSBCINetåˆå§‹åŒ–EEGé€šè·¯")
            feature_extractor = pretrained_ssbcinet.feature_extractor
            fusion_net = pretrained_ssbcinet.fusion
            out_dim = 512  # SSBCINet fusionè¾“å‡ºç»´åº¦
            print("  âœ… æˆåŠŸåŠ è½½äº†è„‘ç”µé€šè·¯åˆå§‹åŒ–æƒé‡")
        else:
            # éšæœºåˆå§‹åŒ–
            print("ğŸ”„ éšæœºåˆå§‹åŒ–EEGé€šè·¯")
            feature_extractor = EEGFeatureExtractor(
                model_name=eeg_model_name,
                in_chans=in_chans,
                n_classes=n_classes,
                input_window_samples=input_window_samples,
            )
            fusion_net = EEGFusionNetwork(feature_extractor.out_dim)
            out_dim = 512  # EEGFusionNetworkè¾“å‡ºç»´åº¦

        return EEGFeaturePath(feature_extractor, fusion_net, out_dim)

    def _build_image_path(self, image_model_name, pretrained_image_model, image_model_type):
        """æ„å»ºå›¾åƒç‰¹å¾æå–é€šè·¯"""
        from image_models import ImageFeatureExtractor

        if pretrained_image_model is not None:
            # ä½¿ç”¨é¢„è®­ç»ƒçš„å›¾åƒæ¨¡å‹
            print(f"âœ… ä½¿ç”¨é¢„è®­ç»ƒçš„{image_model_type.upper()}åˆå§‹åŒ–å›¾åƒé€šè·¯")
            return ImageFeatureExtractor(
                base_model_name=image_model_name,
                pretrained_rsscnn=pretrained_image_model
            )
        else:
            # éšæœºåˆå§‹åŒ–
            print("ğŸ”„ éšæœºåˆå§‹åŒ–å›¾åƒé€šè·¯")
            return ImageFeatureExtractor(
                base_model_name=image_model_name,
                pretrained_rsscnn=None
            )

    def forward(self, eeg1, eeg2, img1, img2):
        """
        å‰å‘ä¼ æ’­
        """
        # æå–EEGç‰¹å¾
        eeg_features = self.eeg_feature_net(eeg1, eeg2)
        eeg_features = self.eeg_projection(eeg_features)

        # æå–å›¾åƒç‰¹å¾
        image_features = self.image_feature_net(img1, img2)
        image_features = self.image_projection(image_features)

        # å¤šæ¨¡æ€èåˆ
        if self.fusion_method == "concatenate":
            fused_features = torch.cat([eeg_features, image_features], dim=1)
        elif self.fusion_method == "add":
            fused_features = eeg_features + image_features
        elif self.fusion_method == "weighted":
            fused_features = self.attention_fusion(eeg_features, image_features)

        # åˆ†ç±»
        logits = self.classifier(fused_features)

        if logits.shape[1] == 1:
            return logits.squeeze()  # äºŒåˆ†ç±»
        else:
            return logits  # å¤šåˆ†ç±»

    def _initialize_weights(self):
        """åªåˆå§‹åŒ–æ–°æ·»åŠ çš„å±‚ï¼ˆæŠ•å½±å±‚å’Œåˆ†ç±»å™¨ï¼‰"""
        for m in self.modules():
            if (isinstance(m, nn.Linear) and
                    m in [layer for layer in self.eeg_projection.modules()] +
                    [layer for layer in self.image_projection.modules()] +
                    [layer for layer in self.classifier.modules()]):
                nn.init.normal_(m.weight, mean=0.0, std=0.01)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0.1)


class CrossModalAttention(nn.Module):
    """è·¨æ¨¡æ€æ³¨æ„åŠ›èåˆæ¨¡å—"""

    def __init__(self, feature_dim):
        super(CrossModalAttention, self).__init__()
        self.feature_dim = feature_dim

        # æ³¨æ„åŠ›æƒé‡è®¡ç®—
        self.eeg_attention = nn.Sequential(
            nn.Linear(feature_dim, feature_dim // 2),
            nn.ReLU(),
            nn.Linear(feature_dim // 2, 1),
            nn.Sigmoid()
        )

        self.image_attention = nn.Sequential(
            nn.Linear(feature_dim, feature_dim // 2),
            nn.ReLU(),
            nn.Linear(feature_dim // 2, 1),
            nn.Sigmoid()
        )

    def forward(self, eeg_features, image_features):
        # è®¡ç®—æ³¨æ„åŠ›æƒé‡
        eeg_weights = self.eeg_attention(eeg_features)
        image_weights = self.image_attention(image_features)

        # å½’ä¸€åŒ–æƒé‡
        total_weights = eeg_weights + image_weights + 1e-8
        eeg_weights = eeg_weights / total_weights
        image_weights = image_weights / total_weights

        # åŠ æƒèåˆ
        fused_features = eeg_weights * eeg_features + image_weights * image_features

        return fused_features


if __name__ == "__main__":

    # æµ‹è¯•æ¨¡å‹åŠ è½½å’Œåˆå§‹åŒ–

    print("=== æ£€æŸ¥å¯ç”¨æ¨¡å‹ ===")
    loader = ModelLoader()
    available = loader.get_available_models()
    print("å¯ç”¨EEGæ¨¡å‹:", available["eeg_models"])
    print("å¯ç”¨RSSCNNæ¨¡å‹:", available["image_models"]["rsscnn"])
    print("å¯ç”¨SSCNNæ¨¡å‹:", available["image_models"]["sscnn"])

    print("\n=== æµ‹è¯•å¤šæ¨¡æ€ç½‘ç»œ ===")

    # æµ‹è¯•1: ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if available["eeg_models"] and available["image_models"]["rsscnn"]:
        eeg_model = available["eeg_models"][0]
        image_model = available["image_models"]["rsscnn"][0]

        print(f"ä½¿ç”¨ {eeg_model} + RSSCNN-{image_model}")

        model = MultiModalFusionNetwork(
            eeg_model_name=eeg_model,
            image_model_name=image_model,
            image_model_type="rsscnn",
            use_pretrained_eeg=True,
            use_pretrained_image=True
        )

        model_sscnn = MultiModalFusionNetwork(
            eeg_model_name=eeg_model,
            image_model_name=image_model,
            image_model_type="sscnn",
            use_pretrained_eeg=True,
            use_pretrained_image=True
        )

        # æµ‹è¯•å‰å‘ä¼ æ’­
        eeg1 = torch.randn(2, 64, 2000)
        eeg2 = torch.randn(2, 64, 2000)
        img1 = torch.randn(2, 3, 224, 224)
        img2 = torch.randn(2, 3, 224, 224)

        output = model(eeg1, eeg2, img1, img2)
        print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")

    # æµ‹è¯•2: éšæœºåˆå§‹åŒ–
    print("\n=== æµ‹è¯•éšæœºåˆå§‹åŒ– ===")
    model_random = MultiModalFusionNetwork(
        use_pretrained_eeg=False,
        use_pretrained_image=False
    )
    output_random = model_random(eeg1, eeg2, img1, img2)
    print(f"éšæœºåˆå§‹åŒ–è¾“å‡ºå½¢çŠ¶: {output_random.shape}")