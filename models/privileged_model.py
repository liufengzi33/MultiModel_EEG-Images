import torch
import torch.nn as nn
import torch.nn.functional as F
import os
from utils.model_loader import ModelLoader


class PrivilegedLearningNetwork(nn.Module):
    def __init__(self,
                 eeg_model_name="EEGNet",
                 image_model_name="PlacesNet",
                 image_model_type="rsscnn",
                 in_chans=64,
                 n_classes=2,
                 input_window_samples=2000,
                 use_pretrained_eeg=True,
                 use_pretrained_image=True,
                 base_path="outputs",
                 common_dim=512,
                 private_dim=256,
                 dropout_rate=0.5,
                 alpha=0.5,  # å…¬å…±æŸå¤±æƒé‡
                 beta=0.5,  # ç§æœ‰æŸå¤±æƒé‡
                 gamma=0.1):  # è’¸é¦æŸå¤±æƒé‡
        """
        ç‰¹æƒå­¦ä¹ ç½‘ç»œ - åŸºäºè„‘æœºè€¦åˆå­¦ä¹ 

        Args:
            gamma: çŸ¥è¯†è’¸é¦æŸå¤±æƒé‡ï¼Œè®©å­¦ç”Ÿç½‘ç»œæ¨¡ä»¿æ•™å¸ˆç½‘ç»œ
        """
        super(PrivilegedLearningNetwork, self).__init__()

        self.alpha = alpha
        self.beta = beta
        self.gamma = gamma
        self.n_classes = n_classes

        # åˆå§‹åŒ–æ¨¡å‹åŠ è½½å™¨
        self.model_loader = ModelLoader(base_path)

        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        pretrained_ssbcinet = None
        pretrained_image_model = None

        if use_pretrained_eeg:
            pretrained_ssbcinet = self.model_loader.load_eeg_model(
                model_name=eeg_model_name,
                in_chans=in_chans,
                n_classes=n_classes,
                input_window_samples=input_window_samples
            )

        if use_pretrained_image:
            pretrained_image_model = self.model_loader.load_image_model(
                model_type=image_model_type,
                base_model_name=image_model_name
            )

        # åˆå§‹åŒ–ç‰¹å¾æå–é€šè·¯
        self.eeg_feature_net = self._build_eeg_path(
            eeg_model_name=eeg_model_name,
            in_chans=in_chans,
            n_classes=n_classes,
            input_window_samples=input_window_samples,
            pretrained_ssbcinet=pretrained_ssbcinet
        )

        self.image_feature_net = self._build_image_path(
            image_model_name=image_model_name,
            pretrained_image_model=pretrained_image_model,
            image_model_type=image_model_type
        )

        # å…¬å…±é€šé“ç¼–ç å™¨ (å…±äº«å‚æ•°)
        self.common_encoder = nn.Sequential(
            nn.Linear(self.eeg_feature_net.out_dim, common_dim),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(common_dim, common_dim),
            nn.ReLU()
        )

        # ç§æœ‰é€šé“ç¼–ç å™¨
        self.eeg_private_encoder = nn.Sequential(
            nn.Linear(self.eeg_feature_net.out_dim, private_dim),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(private_dim, private_dim),
            nn.ReLU()
        )

        self.image_private_encoder = nn.Sequential(
            nn.Linear(self.image_feature_net.out_dim, private_dim),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(private_dim, private_dim),
            nn.ReLU()
        )

        # æ•™å¸ˆåˆ†ç±»å™¨ (ä½¿ç”¨EEG+å›¾åƒï¼Œè®­ç»ƒæ—¶ç”¨)
        teacher_fusion_dim = common_dim + private_dim * 2
        self.teacher_classifier = nn.Sequential(
            nn.Linear(teacher_fusion_dim, 256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(dropout_rate / 2),
            nn.Linear(128, n_classes)
        )

        # å­¦ç”Ÿåˆ†ç±»å™¨ (ä»…ä½¿ç”¨å›¾åƒï¼Œæµ‹è¯•æ—¶ç”¨)
        student_fusion_dim = common_dim + private_dim  # ä»…å›¾åƒå…¬å…±ç‰¹å¾ + å›¾åƒç§æœ‰ç‰¹å¾
        self.student_classifier = nn.Sequential(
            nn.Linear(student_fusion_dim, 256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(dropout_rate / 2),
            nn.Linear(128, n_classes if n_classes > 2 else 1)
        )

        # åˆå§‹åŒ–æƒé‡
        self._initialize_weights()

    def _build_eeg_path(self, eeg_model_name, in_chans, n_classes, input_window_samples, pretrained_ssbcinet):
        """æ„å»ºEEGç‰¹å¾æå–é€šè·¯"""
        from eeg_models import EEGFeatureExtractor, EEGFusionNetwork

        class EEGFeaturePath(nn.Module):
            def __init__(self, feature_extractor, fusion_net, out_dim):
                super(EEGFeaturePath, self).__init__()
                self.feature_extractor = feature_extractor
                self.fusion = fusion_net
                self.out_dim = out_dim

            def forward(self, x1, x2):
                f1 = self.feature_extractor(x1)
                f2 = self.feature_extractor(x2)
                fused = self.fusion(f1, f2)
                return fused

        if pretrained_ssbcinet is not None:
            print("âœ… ä½¿ç”¨é¢„è®­ç»ƒçš„SSBCINetåˆå§‹åŒ–EEGé€šè·¯")
            feature_extractor = pretrained_ssbcinet.feature_extractor
            fusion_net = pretrained_ssbcinet.fusion
            out_dim = 512
        else:
            print("ğŸ”„ éšæœºåˆå§‹åŒ–EEGé€šè·¯")
            feature_extractor = EEGFeatureExtractor(
                model_name=eeg_model_name,
                in_chans=in_chans,
                n_classes=n_classes,
                input_window_samples=input_window_samples,
            )
            fusion_net = EEGFusionNetwork(feature_extractor.out_dim)
            out_dim = 512

        return EEGFeaturePath(feature_extractor, fusion_net, out_dim)

    def _build_image_path(self, image_model_name, pretrained_image_model, image_model_type):
        """æ„å»ºå›¾åƒç‰¹å¾æå–é€šè·¯"""
        from image_models import ImageFeatureExtractor

        if pretrained_image_model is not None:
            print(f"âœ… ä½¿ç”¨é¢„è®­ç»ƒçš„{image_model_type.upper()}åˆå§‹åŒ–å›¾åƒé€šè·¯")
            return ImageFeatureExtractor(
                base_model_name=image_model_name,
                pretrained_rsscnn=pretrained_image_model
            )
        else:
            print("ğŸ”„ éšæœºåˆå§‹åŒ–å›¾åƒé€šè·¯")
            return ImageFeatureExtractor(
                base_model_name=image_model_name,
                pretrained_rsscnn=None
            )

    def forward(self, eeg1, eeg2, img1, img2, mode='train'):
        """
        å‰å‘ä¼ æ’­

        Args:
            mode: 'train' - è®­ç»ƒæ¨¡å¼ï¼Œä½¿ç”¨EEGå’Œå›¾åƒ
                  'test' - æµ‹è¯•æ¨¡å¼ï¼Œä»…ä½¿ç”¨å›¾åƒ
        """
        if mode == 'train':
            return self._forward_train(eeg1, eeg2, img1, img2)
        else:
            return self._forward_test(img1, img2)

    def _forward_train(self, eeg1, eeg2, img1, img2):
        """è®­ç»ƒæ¨¡å¼å‰å‘ä¼ æ’­ - ä½¿ç”¨EEGå’Œå›¾åƒ"""
        # æå–åŸºç¡€ç‰¹å¾
        eeg_base_features = self.eeg_feature_net(eeg1, eeg2)
        image_base_features = self.image_feature_net(img1, img2)

        # å…¬å…±é€šé“ç‰¹å¾
        eeg_common = self.common_encoder(eeg_base_features)
        image_common = self.common_encoder(image_base_features)

        # ç§æœ‰é€šé“ç‰¹å¾
        eeg_private = self.eeg_private_encoder(eeg_base_features)
        image_private = self.image_private_encoder(image_base_features)

        # æ•™å¸ˆç½‘ç»œèåˆç‰¹å¾ (EEGå…¬å…± + EEGç§æœ‰ + å›¾åƒç§æœ‰)
        teacher_fused = torch.cat([eeg_common, eeg_private, image_private], dim=1)
        teacher_logits = self.teacher_classifier(teacher_fused)

        # å­¦ç”Ÿç½‘ç»œèåˆç‰¹å¾ (å›¾åƒå…¬å…± + å›¾åƒç§æœ‰)
        student_fused = torch.cat([image_common, image_private], dim=1)
        student_logits = self.student_classifier(student_fused)

        return {
            'teacher_logits': teacher_logits,
            'student_logits': student_logits,
            'eeg_common': eeg_common,
            'image_common': image_common,
            'eeg_private': eeg_private,
            'image_private': image_private
        }

    def _forward_test(self, img1, img2):
        """æµ‹è¯•æ¨¡å¼å‰å‘ä¼ æ’­ - ä»…ä½¿ç”¨å›¾åƒ"""
        # æå–å›¾åƒåŸºç¡€ç‰¹å¾
        image_base_features = self.image_feature_net(img1, img2)

        # å›¾åƒå…¬å…±é€šé“ç‰¹å¾
        image_common = self.common_encoder(image_base_features)

        # å›¾åƒç§æœ‰é€šé“ç‰¹å¾
        image_private = self.image_private_encoder(image_base_features)

        # å­¦ç”Ÿç½‘ç»œèåˆç‰¹å¾ (å›¾åƒå…¬å…± + å›¾åƒç§æœ‰)
        student_fused = torch.cat([image_common, image_private], dim=1)
        student_logits = self.student_classifier(student_fused)

        if self.n_classes <= 2 and student_logits.shape[1] == 1:
            student_logits = student_logits.squeeze()

        return student_logits

    def compute_loss(self, outputs, targets, temperature=2.0):
        """
        è®¡ç®—ç‰¹æƒå­¦ä¹ çš„æ€»æŸå¤±

        Args:
            temperature: çŸ¥è¯†è’¸é¦çš„æ¸©åº¦å‚æ•°
        """
        teacher_logits = outputs['teacher_logits']
        student_logits = outputs['student_logits']
        eeg_common = outputs['eeg_common']
        image_common = outputs['image_common']
        eeg_private = outputs['eeg_private']
        image_private = outputs['image_private']

        # 1. æ•™å¸ˆç½‘ç»œåˆ†ç±»æŸå¤± (ä½¿ç”¨ç‰¹æƒä¿¡æ¯EEG)
        teacher_loss = F.cross_entropy(teacher_logits, targets)

        # 2. å­¦ç”Ÿç½‘ç»œåˆ†ç±»æŸå¤±
        if self.n_classes <= 2:
            student_loss = F.binary_cross_entropy_with_logits(
                student_logits, targets.float()
            )
        else:
            student_loss = F.cross_entropy(student_logits, targets)

        # 3. çŸ¥è¯†è’¸é¦æŸå¤± - è®©å­¦ç”Ÿæ¨¡ä»¿æ•™å¸ˆçš„è¾“å‡ºåˆ†å¸ƒ
        distill_loss = self.knowledge_distillation_loss(
            teacher_logits, student_logits, temperature
        )

        # 4. å…¬å…±é€šé“ç›¸ä¼¼æ€§æŸå¤±
        common_sim_loss = self.cmd_loss(eeg_common, image_common, K=3)

        # 5. ç§æœ‰é€šé“å·®å¼‚æ€§æŸå¤±
        private_diff_loss = self.orthogonality_loss(
            eeg_common, eeg_private, image_common, image_private
        )

        # æ€»æŸå¤±
        total_loss = (teacher_loss + student_loss +
                      self.gamma * distill_loss +
                      self.alpha * common_sim_loss +
                      self.beta * private_diff_loss)

        return {
            'total_loss': total_loss,
            'teacher_loss': teacher_loss,
            'student_loss': student_loss,
            'distill_loss': distill_loss,
            'common_sim_loss': common_sim_loss,
            'private_diff_loss': private_diff_loss
        }

    def knowledge_distillation_loss(self, teacher_logits, student_logits, temperature):
        """çŸ¥è¯†è’¸é¦æŸå¤± - è®©å­¦ç”Ÿç½‘ç»œæ¨¡ä»¿æ•™å¸ˆç½‘ç»œçš„è¾“å‡ºåˆ†å¸ƒ"""
        # ä½¿ç”¨softmax-temperatureè½¯åŒ–æ¦‚ç‡åˆ†å¸ƒ
        teacher_probs = F.softmax(teacher_logits / temperature, dim=1)
        student_log_probs = F.log_softmax(student_logits / temperature, dim=1)

        # KLæ•£åº¦æŸå¤±
        distill_loss = F.kl_div(student_log_probs, teacher_probs, reduction='batchmean')
        distill_loss *= (temperature ** 2)  # ç¼©æ”¾æŸå¤±

        return distill_loss

    def cmd_loss(self, X, Y, K=3):
        """ä¸­å¿ƒçŸ©å·®å¼‚æŸå¤±"""
        x_mean = torch.mean(X, 0)
        y_mean = torch.mean(Y, 0)
        moment_diff = torch.norm(x_mean - y_mean, 2)

        for k in range(2, K + 1):
            x_moment = torch.mean((X - x_mean) ** k, 0)
            y_moment = torch.mean((Y - y_mean) ** k, 0)
            moment_diff += torch.norm(x_moment - y_moment, 2)

        return moment_diff

    def orthogonality_loss(self, eeg_common, eeg_private, image_common, image_private):
        """æ­£äº¤æ€§æŸå¤±"""
        batch_size = eeg_common.size(0)

        eeg_orth_loss = torch.norm(torch.mm(eeg_common.t(), eeg_private), p='fro') ** 2
        image_orth_loss = torch.norm(torch.mm(image_common.t(), image_private), p='fro') ** 2
        cross_orth_loss = torch.norm(torch.mm(eeg_private.t(), image_private), p='fro') ** 2

        return (eeg_orth_loss + image_orth_loss + cross_orth_loss) / batch_size

    def _initialize_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, mean=0.0, std=0.01)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0.1)


# æµ‹è¯•ç‰¹æƒå­¦ä¹ ç½‘ç»œ
if __name__ == "__main__":
    print("=== æµ‹è¯•ç‰¹æƒå­¦ä¹ ç½‘ç»œ ===")

    model = PrivilegedLearningNetwork(
        use_pretrained_eeg=False,
        use_pretrained_image=False,
        n_classes=7  # 7ç±»æƒ…æ„Ÿåˆ†ç±»
    )
    print(model)
    # è®­ç»ƒæ¨¡å¼æµ‹è¯•
    print("\n=== è®­ç»ƒæ¨¡å¼ ===")
    eeg1 = torch.randn(2, 64, 2000)
    eeg2 = torch.randn(2, 64, 2000)
    img1 = torch.randn(2, 3, 224, 224)
    img2 = torch.randn(2, 3, 224, 224)
    targets = torch.tensor([0, 1])  # åˆ†ç±»æ ‡ç­¾

    outputs = model(eeg1, eeg2, img1, img2, mode='train')
    losses = model.compute_loss(outputs, targets)

    print(f"æ•™å¸ˆç½‘ç»œè¾“å‡ºå½¢çŠ¶: {outputs['teacher_logits'].shape}")
    print(f"å­¦ç”Ÿç½‘ç»œè¾“å‡ºå½¢çŠ¶: {outputs['student_logits'].shape}")

    for loss_name, loss_value in losses.items():
        print(f"{loss_name}: {loss_value.item():.4f}")

    # æµ‹è¯•æ¨¡å¼æµ‹è¯•
    print("\n=== æµ‹è¯•æ¨¡å¼ ===")
    test_output = model(eeg1, eeg2, img1, img2, mode='test')
    print(f"æµ‹è¯•æ¨¡å¼è¾“å‡ºå½¢çŠ¶: {test_output.shape}")

    print("\nâœ… ç‰¹æƒå­¦ä¹ ç½‘ç»œæµ‹è¯•å®Œæˆï¼")
    print("è®­ç»ƒæ—¶ï¼šä½¿ç”¨EEG+å›¾åƒï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦è®©å­¦ç”Ÿç½‘ç»œå­¦ä¹ æ•™å¸ˆç½‘ç»œçš„çŸ¥è¯†")
    print("æµ‹è¯•æ—¶ï¼šä»…ä½¿ç”¨å›¾åƒï¼Œå­¦ç”Ÿç½‘ç»œç‹¬ç«‹å®Œæˆåˆ†ç±»ä»»åŠ¡")