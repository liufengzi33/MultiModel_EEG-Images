import torch
import torch.nn as nn
import torch.nn.functional as F
from models.eeg_models import EEGFeatureExtractor, EEGFusionNetwork
from utils.model_loader import ModelLoader
from models.image_models import ImageFeatureExtractor


class PrivilegedMultimodalNetwork(nn.Module):
    def __init__(self,
                 eeg_model_name="EEGNetv1",
                 image_model_name="PlacesNet",
                 image_model_type="rsscnn",
                 in_chans=64,
                 n_classes=2,
                 input_window_samples=2000,
                 use_pretrained_eeg=True,
                 use_pretrained_image=True,
                 base_path="outputs",
                 common_dim=512,
                 private_dim=256,
                 dropout_rate=0.5,
                 alpha=0.5,  # å…¬å…±æŸå¤±æƒé‡
                 beta=0.5,  # ç§æœ‰æŸå¤±æƒé‡
                 gamma=0.3,  # çŸ¥è¯†è’¸é¦æŸå¤±æƒé‡
                 temperature=2.0):  # è’¸é¦æ¸©åº¦
        """
        ç‰¹æƒå­¦ä¹ å¤šæ¨¡æ€ç½‘ç»œ

        Args:
            gamma: çŸ¥è¯†è’¸é¦æŸå¤±æƒé‡
            temperature: è’¸é¦æ¸©åº¦å‚æ•°
        """
        super(PrivilegedMultimodalNetwork, self).__init__()

        self.alpha = alpha
        self.beta = beta
        self.gamma = gamma
        self.temperature = temperature
        self.n_classes = n_classes

        # åˆå§‹åŒ–æ¨¡å‹åŠ è½½å™¨
        self.model_loader = ModelLoader(base_path)

        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        pretrained_ssbcinet = None
        pretrained_image_model = None

        if use_pretrained_eeg:
            pretrained_ssbcinet = self.model_loader.load_eeg_model(
                model_name=eeg_model_name,
                in_chans=in_chans,
                n_classes=n_classes,
                input_window_samples=input_window_samples
            )

        if use_pretrained_image:
            pretrained_image_model = self.model_loader.load_image_model(
                model_type=image_model_type,
                base_model_name=image_model_name
            )

        # 1. æ„å»ºå®Œæ•´çš„å¤šæ¨¡æ€æ•™å¸ˆç½‘ç»œï¼ˆè®­ç»ƒæ—¶ä½¿ç”¨ï¼‰
        self.teacher_network = self._build_teacher_network(
            eeg_model_name=eeg_model_name,
            image_model_name=image_model_name,
            image_model_type=image_model_type,
            in_chans=in_chans,
            n_classes=n_classes,
            input_window_samples=input_window_samples,
            pretrained_ssbcinet=pretrained_ssbcinet,
            pretrained_image_model=pretrained_image_model,
            common_dim=common_dim,
            private_dim=private_dim,
            dropout_rate=dropout_rate
        )

        # 2. æ„å»ºä»…å›¾åƒçš„å­¦ç”Ÿç½‘ç»œï¼ˆæµ‹è¯•æ—¶ä½¿ç”¨ï¼‰
        self.student_network = self._build_student_network(
            image_model_name=image_model_name,
            pretrained_image_model=pretrained_image_model,
            image_model_type=image_model_type,
            common_dim=common_dim,
            private_dim=private_dim,
            dropout_rate=dropout_rate,
            n_classes=n_classes
        )

    def _build_teacher_network(self, eeg_model_name, image_model_name, image_model_type,
                               in_chans, n_classes, input_window_samples,
                               pretrained_ssbcinet, pretrained_image_model,
                               common_dim, private_dim, dropout_rate):
        """æ„å»ºå®Œæ•´çš„æ•™å¸ˆç½‘ç»œï¼ˆå¤šæ¨¡æ€ï¼‰"""

        # EEGç‰¹å¾æå–é€šè·¯
        class EEGFeaturePath(nn.Module):
            def __init__(self, feature_extractor, fusion_net, out_dim):
                super(EEGFeaturePath, self).__init__()
                self.feature_extractor = feature_extractor
                self.fusion = fusion_net
                self.out_dim = out_dim

            def forward(self, x1, x2):
                f1 = self.feature_extractor(x1)
                f2 = self.feature_extractor(x2)
                fused = self.fusion(f1, f2)
                return fused

        if pretrained_ssbcinet is not None:
            print("âœ… ä½¿ç”¨é¢„è®­ç»ƒçš„SSBCINetåˆå§‹åŒ–æ•™å¸ˆç½‘ç»œEEGé€šè·¯")
            eeg_feature_extractor = pretrained_ssbcinet.feature_extractor
            eeg_fusion_net = pretrained_ssbcinet.fusion
            eeg_out_dim = 512
        else:
            print("ğŸ”„ éšæœºåˆå§‹åŒ–æ•™å¸ˆç½‘ç»œEEGé€šè·¯")
            eeg_feature_extractor = EEGFeatureExtractor(
                model_name=eeg_model_name,
                in_chans=in_chans,
                n_classes=n_classes,
                input_window_samples=input_window_samples,
            )
            eeg_fusion_net = EEGFusionNetwork(eeg_feature_extractor.out_dim)
            eeg_out_dim = 512

        eeg_path = EEGFeaturePath(eeg_feature_extractor, eeg_fusion_net, eeg_out_dim)

        # å›¾åƒç‰¹å¾æå–é€šè·¯
        if pretrained_image_model is not None:
            print(f"âœ… ä½¿ç”¨é¢„è®­ç»ƒçš„{image_model_type.upper()}åˆå§‹åŒ–æ•™å¸ˆç½‘ç»œå›¾åƒé€šè·¯")
            image_path = ImageFeatureExtractor(
                base_model_name=image_model_name,
                pretrained_rsscnn=pretrained_image_model
            )
        else:
            print("ğŸ”„ éšæœºåˆå§‹åŒ–æ•™å¸ˆç½‘ç»œå›¾åƒé€šè·¯")
            image_path = ImageFeatureExtractor(
                base_model_name=image_model_name,
                pretrained_rsscnn=None
            )

        # æ•™å¸ˆç½‘ç»œçš„ç‰¹å¾ç¼–ç å™¨å’Œåˆ†ç±»å™¨
        common_encoder = nn.Sequential(
            nn.Linear(eeg_out_dim, common_dim),  # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾EEGå’Œå›¾åƒç‰¹å¾ç»´åº¦ç›¸åŒ
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(common_dim, common_dim),
            nn.ReLU()
        )

        eeg_private_encoder = nn.Sequential(
            nn.Linear(eeg_out_dim, private_dim),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(private_dim, private_dim),
            nn.ReLU()
        )

        image_private_encoder = nn.Sequential(
            nn.Linear(image_path.out_dim, private_dim),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(private_dim, private_dim),
            nn.ReLU()
        )

        fusion_dim = common_dim + private_dim * 2
        classifier = nn.Sequential(
            nn.Linear(fusion_dim, 256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(dropout_rate / 2),
            nn.Linear(128, n_classes if n_classes > 2 else 1)
        )

        return nn.ModuleDict({
            'eeg_path': eeg_path,
            'image_path': image_path,
            'common_encoder': common_encoder,
            'eeg_private_encoder': eeg_private_encoder,
            'image_private_encoder': image_private_encoder,
            'classifier': classifier
        })

    def _build_student_network(self, image_model_name, pretrained_image_model,
                               image_model_type, common_dim, private_dim,
                               dropout_rate, n_classes):
        """æ„å»ºä»…å›¾åƒçš„å­¦ç”Ÿç½‘ç»œ"""

        # å›¾åƒç‰¹å¾æå–
        if pretrained_image_model is not None:
            print(f"âœ… ä½¿ç”¨é¢„è®­ç»ƒçš„{image_model_type.upper()}åˆå§‹åŒ–å­¦ç”Ÿç½‘ç»œ")
            image_path = ImageFeatureExtractor(
                base_model_name=image_model_name,
                pretrained_rsscnn=pretrained_image_model
            )
        else:
            print("ğŸ”„ éšæœºåˆå§‹åŒ–å­¦ç”Ÿç½‘ç»œ")
            image_path = ImageFeatureExtractor(
                base_model_name=image_model_name,
                pretrained_rsscnn=None
            )

        # å­¦ç”Ÿç½‘ç»œçš„ç‰¹å¾ç¼–ç å™¨å’Œåˆ†ç±»å™¨
        feature_encoder = nn.Sequential(
            nn.Linear(image_path.out_dim, common_dim),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(common_dim, common_dim),
            nn.ReLU()
        )

        classifier = nn.Sequential(
            nn.Linear(common_dim, 256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(dropout_rate / 2),
            nn.Linear(128, n_classes if n_classes > 2 else 1)
        )

        return nn.ModuleDict({
            'image_path': image_path,
            'feature_encoder': feature_encoder,
            'classifier': classifier
        })

    def forward(self, eeg1=None, eeg2=None, img1=None, img2=None, mode='train'):
        """
        å‰å‘ä¼ æ’­

        Args:
            mode: 'train' - è®­ç»ƒæ¨¡å¼ï¼Œä½¿ç”¨å®Œæ•´å¤šæ¨¡æ€ä¿¡æ¯
                  'test' - æµ‹è¯•æ¨¡å¼ï¼Œä»…ä½¿ç”¨å›¾åƒä¿¡æ¯
        """
        if mode == 'train':
            return self._forward_train(eeg1, eeg2, img1, img2)
        else:
            return self._forward_test(img1, img2)

    def _forward_train(self, eeg1, eeg2, img1, img2):
        """è®­ç»ƒé˜¶æ®µå‰å‘ä¼ æ’­ - ä½¿ç”¨å®Œæ•´å¤šæ¨¡æ€ä¿¡æ¯"""

        # æ•™å¸ˆç½‘ç»œï¼ˆå¤šæ¨¡æ€ï¼‰å‰å‘ä¼ æ’­
        eeg_base_features = self.teacher_network['eeg_path'](eeg1, eeg2)
        image_base_features_teacher = self.teacher_network['image_path'](img1, img2)

        # å…¬å…±é€šé“ç‰¹å¾
        eeg_common = self.teacher_network['common_encoder'](eeg_base_features)
        image_common_teacher = self.teacher_network['common_encoder'](image_base_features_teacher)

        # ç§æœ‰é€šé“ç‰¹å¾
        eeg_private = self.teacher_network['eeg_private_encoder'](eeg_base_features)
        image_private_teacher = self.teacher_network['image_private_encoder'](image_base_features_teacher)

        # ç‰¹å¾èåˆ
        fused_features = torch.cat([eeg_common, eeg_private, image_private_teacher], dim=1)

        # æ•™å¸ˆç½‘ç»œåˆ†ç±»è¾“å‡º
        teacher_logits = self.teacher_network['classifier'](fused_features)
        if teacher_logits.shape[1] == 1:
            teacher_logits = teacher_logits.squeeze()

        # å­¦ç”Ÿç½‘ç»œï¼ˆä»…å›¾åƒï¼‰å‰å‘ä¼ æ’­
        image_base_features_student = self.student_network['image_path'](img1, img2)
        student_features = self.student_network['feature_encoder'](image_base_features_student)
        student_logits = self.student_network['classifier'](student_features)
        if student_logits.shape[1] == 1:
            student_logits = student_logits.squeeze()

        return {
            'teacher_logits': teacher_logits,
            'student_logits': student_logits,
            'eeg_common': eeg_common,
            'image_common_teacher': image_common_teacher,
            'eeg_private': eeg_private,
            'image_private_teacher': image_private_teacher,
            'student_features': student_features
        }

    def _forward_test(self, img1, img2):
        """æµ‹è¯•é˜¶æ®µå‰å‘ä¼ æ’­ - ä»…ä½¿ç”¨å›¾åƒä¿¡æ¯"""
        image_base_features = self.student_network['image_path'](img1, img2)
        features = self.student_network['feature_encoder'](image_base_features)
        logits = self.student_network['classifier'](features)

        if logits.shape[1] == 1:
            logits = logits.squeeze()

        return logits

    def compute_loss(self, outputs, targets):
        """
        è®¡ç®—ç‰¹æƒå­¦ä¹ æ€»æŸå¤±

        åŒ…å«ï¼š
        1. æ•™å¸ˆç½‘ç»œåˆ†ç±»æŸå¤±
        2. å­¦ç”Ÿç½‘ç»œåˆ†ç±»æŸå¤±
        3. çŸ¥è¯†è’¸é¦æŸå¤±
        4. ç‰¹å¾å¯¹é½æŸå¤±
        """
        teacher_logits = outputs['teacher_logits']
        student_logits = outputs['student_logits']
        eeg_common = outputs['eeg_common']
        image_common_teacher = outputs['image_common_teacher']
        eeg_private = outputs['eeg_private']
        image_private_teacher = outputs['image_private_teacher']
        student_features = outputs['student_features']

        # 1. æ•™å¸ˆç½‘ç»œåˆ†ç±»æŸå¤±
        if teacher_logits.dim() == 1:
            teacher_loss = F.binary_cross_entropy_with_logits(teacher_logits, targets.float())
        else:
            teacher_loss = F.cross_entropy(teacher_logits, targets)

        # 2. å­¦ç”Ÿç½‘ç»œåˆ†ç±»æŸå¤±
        if student_logits.dim() == 1:
            student_loss = F.binary_cross_entropy_with_logits(student_logits, targets.float())
        else:
            student_loss = F.cross_entropy(student_logits, targets)

        # 3. çŸ¥è¯†è’¸é¦æŸå¤±
        distill_loss = self.distillation_loss(teacher_logits, student_logits)

        # 4. ç‰¹å¾å¯¹é½æŸå¤±ï¼ˆè®©å­¦ç”Ÿç½‘ç»œå­¦ä¹ æ•™å¸ˆç½‘ç»œçš„ç‰¹å¾è¡¨ç¤ºï¼‰
        feature_align_loss = F.mse_loss(
            student_features,
            image_common_teacher.detach()  # ä½¿ç”¨æ•™å¸ˆç½‘ç»œçš„å›¾åƒå…¬å…±ç‰¹å¾ä½œä¸ºç›®æ ‡
        )

        # 5. å¤šæ¨¡æ€ä¸€è‡´æ€§æŸå¤±ï¼ˆåŸç½‘ç»œä¸­çš„æŸå¤±ï¼‰
        common_sim_loss = self.cmd_loss(eeg_common, image_common_teacher, K=3)
        private_diff_loss = self.orthogonality_loss(eeg_common, eeg_private,
                                                    image_common_teacher, image_private_teacher)

        # æ€»æŸå¤±
        total_loss = (teacher_loss + student_loss +
                      self.gamma * distill_loss +
                      0.1 * feature_align_loss +  # ç‰¹å¾å¯¹é½æŸå¤±æƒé‡
                      self.alpha * common_sim_loss +
                      self.beta * private_diff_loss)

        return {
            'total_loss': total_loss,
            'teacher_loss': teacher_loss,
            'student_loss': student_loss,
            'distill_loss': distill_loss,
            'feature_align_loss': feature_align_loss,
            'common_sim_loss': common_sim_loss,
            'private_diff_loss': private_diff_loss
        }

    def distillation_loss(self, teacher_logits, student_logits):
        """çŸ¥è¯†è’¸é¦æŸå¤±"""
        if teacher_logits.dim() == 1:  # äºŒåˆ†ç±»
            # å°†logitsè½¬æ¢ä¸ºæ¦‚ç‡
            teacher_probs = torch.sigmoid(teacher_logits / self.temperature)
            student_probs = torch.sigmoid(student_logits / self.temperature)
            distill_loss = F.binary_cross_entropy(student_probs, teacher_probs.detach())
        else:  # å¤šåˆ†ç±»
            teacher_probs = F.softmax(teacher_logits / self.temperature, dim=1)
            student_probs = F.softmax(student_logits / self.temperature, dim=1)
            distill_loss = F.kl_div(
                student_probs.log(),
                teacher_probs.detach(),
                reduction='batchmean'
            ) * (self.temperature ** 2)

        return distill_loss

    def cmd_loss(self, X, Y, K=3):
        """ä¸­å¿ƒçŸ©å·®å¼‚æŸå¤±"""
        x_mean = torch.mean(X, 0)
        y_mean = torch.mean(Y, 0)
        moment_diff = torch.norm(x_mean - y_mean, p=2)
        diffs = [moment_diff]

        for k in range(2, K + 1):
            x_moment = torch.mean((X - x_mean) ** k, dim=0)
            y_moment = torch.mean((Y - y_mean) ** k, dim=0)
            diffs.append(torch.norm(x_moment - y_moment, p=2))

        return sum(diffs)

    def orthogonality_loss(self, eeg_common, eeg_private, image_common, image_private):
        """æ­£äº¤æ€§æŸå¤±"""

        def dimension_aware_loss(A, B):
            min_dim = min(A.size(1), B.size(1))
            A_trim = A[:, :min_dim]
            B_trim = B[:, :min_dim]
            A_norm = F.normalize(A_trim, p=2, dim=1)
            B_norm = F.normalize(B_trim, p=2, dim=1)
            cosine_sim = (A_norm * B_norm).sum(dim=1)
            return cosine_sim.abs().mean()

        loss1 = dimension_aware_loss(eeg_common, eeg_private)
        loss2 = dimension_aware_loss(image_common, image_private)
        loss3 = dimension_aware_loss(eeg_private, image_private)

        return (loss1 + loss2 + loss3) / 3.0

# æµ‹è¯•ç‰¹æƒå­¦ä¹ ç½‘ç»œ
if __name__ == "__main__":
    print("=== æµ‹è¯•ç‰¹æƒå­¦ä¹ ç½‘ç»œ ===")

    # åˆ›å»ºæ¨¡å‹
    model = PrivilegedMultimodalNetwork(
        use_pretrained_eeg=True,
        use_pretrained_image=True,
    )

    print("æ¨¡å‹ç»“æ„:")
    print(model)

    # æµ‹è¯•è®­ç»ƒæ¨¡å¼
    print("\n--- è®­ç»ƒæ¨¡å¼æµ‹è¯• (å¤šæ¨¡æ€) ---")
    eeg1 = torch.randn(2, 64, 2000)
    eeg2 = torch.randn(2, 64, 2000)
    img1 = torch.randn(2, 3, 224, 224)
    img2 = torch.randn(2, 3, 224, 224)
    targets = torch.randint(0, 2, (2,)).float()

    # è®­ç»ƒå‰å‘ä¼ æ’­
    outputs = model(eeg1, eeg2, img1, img2, mode='train')
    print(f"æ•™å¸ˆlogitså½¢çŠ¶: {outputs['teacher_logits'].shape}")
    print(f"å­¦ç”Ÿlogitså½¢çŠ¶: {outputs['student_logits'].shape}")

    # è®¡ç®—æŸå¤±
    losses = model.compute_loss(outputs, targets)
    print(f"æ€»æŸå¤±: {losses['total_loss']:.4f}")
    print(f"æ•™å¸ˆæŸå¤±: {losses['teacher_loss']:.4f}")
    print(f"å­¦ç”ŸæŸå¤±: {losses['student_loss']:.4f}")
    print(f"è’¸é¦æŸå¤±: {losses['distill_loss']:.4f}")

    # æµ‹è¯•æµ‹è¯•æ¨¡å¼
    print("\n--- æµ‹è¯•æ¨¡å¼æµ‹è¯• (ä»…å›¾åƒ) ---")
    test_logits = model(img1=img1, img2=img2, mode='test')
    print(f"æµ‹è¯•logitså½¢çŠ¶: {test_logits.shape}")