import torch
import torch.optim as optim
import time
from datetime import datetime
import matplotlib.pyplot as plt
from MyPP2Dataset import MyPP2Dataset, create_dataloaders
from models.multi_model import MultiModalFusionNetwork
from config import config_multi_model
import os
from tqdm import tqdm


class MultiStageTrainer:
    def __init__(self, config):
        self.config = config
        self.device = config.device
        self.history = {
            'stage1': [], 'stage2': [], 'stage3': [],
            'all_train_loss': [], 'all_val_loss': [],
            'all_train_acc': [], 'all_val_acc': [],
            'all_task_loss': [], 'all_common_sim_loss': [], 'all_private_diff_loss': []
        }

    def setup_data(self):
        """æ•°æ®å‡†å¤‡"""
        dataset = MyPP2Dataset(
            is_flipped=False,
            transform=self.config.transform,
            subject_id=self.config.subject_id
        )
        self.train_loader, self.test_loader = create_dataloaders(
            dataset=dataset,
            batch_size=self.config.batch_size,
            shuffle=True
        )

        # æ£€æŸ¥æ•°æ®åˆ†å¸ƒ
        train_labels = [label for _, _, _, _, label in self.train_loader.dataset]
        test_labels = [label for _, _, _, _, label in self.test_loader.dataset]

        print(f"è®­ç»ƒé›†åˆ†å¸ƒ: {torch.bincount(torch.tensor(train_labels)).tolist()}")
        print(f"æµ‹è¯•é›†åˆ†å¸ƒ: {torch.bincount(torch.tensor(test_labels)).tolist()}")
        print(f"è®­ç»ƒé›†: {len(self.train_loader.dataset)}, æµ‹è¯•é›†: {len(self.test_loader.dataset)}")

    def setup_model(self):
        """æ¨¡å‹åˆå§‹åŒ–"""
        self.model = MultiModalFusionNetwork(
            eeg_model_name=self.config.base_eeg_model,
            image_model_name=self.config.base_image_model,
            image_model_type=self.config.image_model_type,
            in_chans=64,
            n_classes=2,
            input_window_samples=2000,
            freeze_eeg_backbone=False,
            freeze_image_backbone=False,
            common_dim=512,
            private_dim=256,
            dropout_rate=0.5,
            alpha=self.config.alpha,
            beta=self.config.beta,
        ).to(self.device)

        # å‚æ•°ç»Ÿè®¡
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        print(f"æ€»å‚æ•°: {total_params:,}, å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

    def freeze_backbones(self):
        """å†»ç»“backbone"""
        for p in self.model.eeg_feature_net.parameters():
            p.requires_grad = False
        for p in self.model.image_feature_net.parameters():
            p.requires_grad = False
        print("ğŸ”’ å†»ç»“æ‰€æœ‰backboneå‚æ•°")

    def unfreeze_backbone_last_layers(self, eeg_layers=4, img_layers=4):
        """è§£å†»backboneæœ€åå‡ å±‚ - ä¼˜åŒ–ç‰ˆæœ¬"""

        # EEGè§£å†»ç­–ç•¥
        eeg_modules = list(self.model.eeg_feature_net.feature_extractor.feature_net.children())

        # è§£å†»EEGæœ€åå‡ å±‚ï¼ˆä»åå¾€å‰ï¼‰
        eeg_unfreeze_indices = list(range(len(eeg_modules)))[-eeg_layers:]
        for idx in eeg_unfreeze_indices:
            for p in eeg_modules[idx].parameters():
                p.requires_grad = True
        print(f"ğŸ”“ è§£å†»EEGå±‚: {eeg_unfreeze_indices} - {[type(m).__name__ for m in eeg_modules[-eeg_layers:]]}")

        # Imageè§£å†»ç­–ç•¥
        img_modules = list(self.model.image_feature_net.feature_extractor.features.children())

        # è§£å†»Imageæœ€åå‡ å±‚ï¼ˆä»åå¾€å‰ï¼‰
        img_unfreeze_indices = list(range(len(img_modules)))[-img_layers:]
        for idx in img_unfreeze_indices:
            for p in img_modules[idx].parameters():
                p.requires_grad = True
        print(f"ğŸ”“ è§£å†»Imageå±‚: {img_unfreeze_indices} - {[type(m).__name__ for m in img_modules[-img_layers:]]}")

        # é¢å¤–è§£å†»èåˆå±‚ï¼ˆé‡è¦ï¼ï¼‰
        for p in self.model.eeg_feature_net.fusion.parameters():
            p.requires_grad = True
        for p in self.model.image_feature_net.fusion_convs.parameters():
            p.requires_grad = True
        print("ğŸ”“ é¢å¤–è§£å†»èåˆå±‚")

    def unfreeze_heads(self):
        """è§£å†»headç½‘ç»œ"""
        for p in self.model.common_encoder.parameters():
            p.requires_grad = True
        for p in self.model.eeg_private_encoder.parameters():
            p.requires_grad = True
        for p in self.model.image_private_encoder.parameters():
            p.requires_grad = True
        for p in self.model.classifier.parameters():
            p.requires_grad = True
        print("ğŸ”“ è§£å†»headç½‘ç»œ")

    def build_optimizer(self, lr_head, lr_backbone):
        """æ„å»ºåˆ†ç»„ä¼˜åŒ–å™¨"""
        head_params = []
        backbone_params = []

        for name, p in self.model.named_parameters():
            if p.requires_grad:
                if "feature_net" in name:
                    backbone_params.append(p)
                else:
                    head_params.append(p)

        param_groups = []
        if head_params:
            param_groups.append({'params': head_params, 'lr': lr_head})
        if backbone_params:
            param_groups.append({'params': backbone_params, 'lr': lr_backbone})

        optimizer = torch.optim.AdamW(param_groups, weight_decay=self.config.weight_decay)

        print(f"ğŸ”§ ä¼˜åŒ–å™¨: head_lr={lr_head}, backbone_lr={lr_backbone}")
        print(f"   å¯è®­ç»ƒå‚æ•°: head={len(head_params)}ç»„, backbone={len(backbone_params)}ç»„")

        return optimizer

    def train_stage(self, stage_name, lr_head, lr_backbone,
                    max_epochs, patience=5, min_epochs=10):
        """
        æ™ºèƒ½è®­ç»ƒé˜¶æ®µ
        Args:
            patience: éªŒè¯æŸå¤±ä¸æ”¹å–„çš„å®¹å¿è½®æ¬¡
            min_epochs: æœ€å°è®­ç»ƒè½®æ¬¡
        """
        print(f"\n{'=' * 50}")
        print(f"é˜¶æ®µ: {stage_name}")
        print(f"{'=' * 50}")

        # ä¼˜åŒ–å™¨
        optimizer = self.build_optimizer(lr_head, lr_backbone)

        # å­¦ä¹ ç‡è°ƒåº¦ - ä½¿ç”¨CosineAnnealingWarmRestartsæ›´å¹³æ»‘
        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            optimizer, T_0=min_epochs, T_mult=1, eta_min=lr_head * 0.01
        )

        best_val_loss = float('inf')
        no_improve_count = 0
        stage_history = []

        start_time = time.time()

        for epoch in range(max_epochs):
            # è®­ç»ƒ
            train_results = self.train_epoch(optimizer, epoch, max_epochs, stage_name)
            train_loss, train_acc, task_loss, common_sim_loss, private_diff_loss = train_results

            # éªŒè¯
            val_results = self.validate_epoch(epoch, max_epochs, stage_name)
            val_loss, val_acc, val_task_loss, val_common_sim_loss, val_private_diff_loss = val_results

            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step()
            current_lr = optimizer.param_groups[0]['lr']

            # è®°å½•å†å²
            stage_history.append({
                'epoch': epoch + 1,
                'train_loss': train_loss, 'val_loss': val_loss,
                'train_acc': train_acc, 'val_acc': val_acc,
                'lr': current_lr,
                'task_loss': task_loss, 'common_sim_loss': common_sim_loss,
                'private_diff_loss': private_diff_loss,
                'val_task_loss': val_task_loss, 'val_common_sim_loss': val_common_sim_loss,
                'val_private_diff_loss': val_private_diff_loss
            })

            self.history['all_train_loss'].append(train_loss)
            self.history['all_val_loss'].append(val_loss)
            self.history['all_train_acc'].append(train_acc)
            self.history['all_val_acc'].append(val_acc)
            self.history['all_task_loss'].append(task_loss)
            self.history['all_common_sim_loss'].append(common_sim_loss)
            self.history['all_private_diff_loss'].append(private_diff_loss)

            # æ—©åœåˆ¤æ–­
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                no_improve_count = 0
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'val_loss': val_loss,
                    'val_acc': val_acc,
                    'stage': stage_name
                }, os.path.join(self.save_dir, f'best_{stage_name}.pth'))
                print(f"  âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (val_loss: {val_loss:.4f})")
            else:
                no_improve_count += 1

            # æ‰“å°è¿›åº¦
            if (epoch + 1) % 5 == 0 or epoch == 0:
                print(f"\nEpoch {epoch + 1}/{max_epochs} æ€»ç»“:")
                print(f"  è®­ç»ƒ - æ€»æŸå¤±: {train_loss:.4f}, ä»»åŠ¡æŸå¤±: {task_loss:.4f}, "
                      f"å…±åŒç‰¹å¾ç›¸ä¼¼åº¦æŸå¤±: {common_sim_loss:.4f}, ç§æœ‰ç‰¹å¾å·®å¼‚æŸå¤±: {private_diff_loss:.4f}")
                print(f"  è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.2f}%")
                print(f"  éªŒè¯ - æ€»æŸå¤±: {val_loss:.4f}, ä»»åŠ¡æŸå¤±: {val_task_loss:.4f}, "
                      f"å…±åŒç‰¹å¾ç›¸ä¼¼åº¦æŸå¤±: {val_common_sim_loss:.4f}, ç§æœ‰ç‰¹å¾å·®å¼‚æŸå¤±: {val_private_diff_loss:.4f}")
                print(f"  éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%")
                print(f"  å­¦ä¹ ç‡: {current_lr:.2e}, æ— æ”¹å–„è½®æ¬¡: {no_improve_count}/{patience}")

            # æ—©åœæ¡ä»¶
            if no_improve_count >= patience and epoch >= min_epochs:
                print(f"ğŸ›‘ {stage_name} æ—©åœäºç¬¬ {epoch + 1} è½®")
                break

        training_time = time.time() - start_time
        print(f"â±ï¸  {stage_name} è®­ç»ƒæ—¶é—´: {training_time / 60:.1f}åˆ†é’Ÿ")

        self.history[stage_name] = stage_history
        return stage_history

    def train_epoch(self, optimizer, epoch, max_epochs, stage_name):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        train_loss = 0.0
        train_task_loss = 0.0
        train_common_sim_loss = 0.0
        train_private_diff_loss = 0.0
        train_correct = 0
        train_total = 0

        # åˆ›å»ºtqdmè¿›åº¦æ¡
        pbar = tqdm(self.train_loader, desc=f'{stage_name} Epoch {epoch + 1}/{max_epochs} [è®­ç»ƒ]')

        for batch_idx, (left_img, right_img, left_eeg, right_eeg, labels) in enumerate(pbar):
            # æ•°æ®è¿ç§»
            left_img = left_img.to(self.device)
            right_img = right_img.to(self.device)
            left_eeg = left_eeg.to(self.device)
            right_eeg = right_eeg.to(self.device)
            labels = labels.to(self.device)

            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            logits, eeg_common, image_common, eeg_private, image_private = self.model(
                left_eeg, right_eeg, left_img, right_img
            )

            # æŸå¤±è®¡ç®—
            losses = self.model.compute_loss(
                eeg_common, image_common, eeg_private, image_private, logits, labels
            )

            total_loss = losses['total_loss']
            task_loss = losses['task_loss']
            common_sim_loss = losses['common_sim_loss']
            private_diff_loss = losses['private_diff_loss']

            # åå‘ä¼ æ’­
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)  # æ¢¯åº¦è£å‰ª
            optimizer.step()

            # ç»Ÿè®¡
            train_loss += total_loss.item()
            train_task_loss += task_loss.item()
            train_common_sim_loss += common_sim_loss.item()
            train_private_diff_loss += private_diff_loss.item()

            preds = (logits.squeeze() > 0).long() if logits.dim() == 1 else torch.argmax(logits, dim=1)
            train_correct += (preds == labels).sum().item()
            train_total += labels.size(0)

            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'æ€»æŸå¤±': f'{total_loss.item():.4f}',
                'ä»»åŠ¡æŸå¤±': f'{task_loss.item():.4f}',
                'å…±åŒæŸå¤±': f'{common_sim_loss.item():.4f}',
                'ç§æœ‰æŸå¤±': f'{private_diff_loss.item():.4f}',
                'å‡†ç¡®ç‡': f'{100.0 * train_correct / train_total:.2f}%'
            })

        # è®¡ç®—epochå¹³å‡å€¼
        avg_train_loss = train_loss / len(self.train_loader)
        avg_task_loss = train_task_loss / len(self.train_loader)
        avg_common_sim_loss = train_common_sim_loss / len(self.train_loader)
        avg_private_diff_loss = train_private_diff_loss / len(self.train_loader)
        train_accuracy = 100.0 * train_correct / train_total

        return avg_train_loss, train_accuracy, avg_task_loss, avg_common_sim_loss, avg_private_diff_loss

    def validate_epoch(self, epoch, max_epochs, stage_name):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        val_loss = 0.0
        val_task_loss = 0.0
        val_common_sim_loss = 0.0
        val_private_diff_loss = 0.0
        val_correct = 0
        val_total = 0

        # åˆ›å»ºtqdmè¿›åº¦æ¡
        pbar = tqdm(self.test_loader, desc=f'{stage_name} Epoch {epoch + 1}/{max_epochs} [éªŒè¯]')

        with torch.no_grad():
            for batch_idx, (left_img, right_img, left_eeg, right_eeg, labels) in enumerate(pbar):
                # æ•°æ®è¿ç§»
                left_img = left_img.to(self.device)
                right_img = right_img.to(self.device)
                left_eeg = left_eeg.to(self.device)
                right_eeg = right_eeg.to(self.device)
                labels = labels.to(self.device)

                # å‰å‘ä¼ æ’­
                logits, eeg_common, image_common, eeg_private, image_private = self.model(
                    left_eeg, right_eeg, left_img, right_img
                )

                # æŸå¤±è®¡ç®—
                losses = self.model.compute_loss(
                    eeg_common, image_common, eeg_private, image_private, logits, labels
                )

                total_loss = losses['total_loss']
                task_loss = losses['task_loss']
                common_sim_loss = losses['common_sim_loss']
                private_diff_loss = losses['private_diff_loss']

                val_loss += total_loss.item()
                val_task_loss += task_loss.item()
                val_common_sim_loss += common_sim_loss.item()
                val_private_diff_loss += private_diff_loss.item()

                preds = (logits.squeeze() > 0).long() if logits.dim() == 1 else torch.argmax(logits, dim=1)
                val_correct += (preds == labels).sum().item()
                val_total += labels.size(0)

                # æ›´æ–°è¿›åº¦æ¡
                pbar.set_postfix({
                    'æ€»æŸå¤±': f'{total_loss.item():.4f}',
                    'ä»»åŠ¡æŸå¤±': f'{task_loss.item():.4f}',
                    'å…±åŒæŸå¤±': f'{common_sim_loss.item():.4f}',
                    'ç§æœ‰æŸå¤±': f'{private_diff_loss.item():.4f}',
                    'å‡†ç¡®ç‡': f'{100.0 * val_correct / val_total:.2f}%'
                })

        # è®¡ç®—epochå¹³å‡å€¼
        avg_val_loss = val_loss / len(self.test_loader)
        avg_val_task_loss = val_task_loss / len(self.test_loader)
        avg_val_common_sim_loss = val_common_sim_loss / len(self.test_loader)
        avg_val_private_diff_loss = val_private_diff_loss / len(self.test_loader)
        val_accuracy = 100.0 * val_correct / val_total

        return avg_val_loss, val_accuracy, avg_val_task_loss, avg_val_common_sim_loss, avg_val_private_diff_loss

    def train(self):
        """ä¸»è®­ç»ƒæµç¨‹"""
        # è®¾ç½®ä¿å­˜ç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.save_dir = f"outputs/outputs_multi_model/{self.config.base_eeg_model}+{self.config.base_image_model}_{self.config.image_model_type}/multimodal_{timestamp}"
        os.makedirs(self.save_dir, exist_ok=True)

        # é˜¶æ®µ1: å¿«é€Ÿæ”¶æ•›head
        self.freeze_backbones()
        self.unfreeze_heads()
        self.train_stage(
            stage_name="stage1_freeze_backbone",
            lr_head=1e-3,
            lr_backbone=0,
            max_epochs=30,
            patience=8,
            min_epochs=10
        )

        # é˜¶æ®µ2: å¼ºåŒ–å¯¹é½
        self.freeze_backbones()
        self.unfreeze_heads()
        self.train_stage(
            stage_name="stage2_align_features",
            lr_head=5e-4,
            lr_backbone=0,
            max_epochs=80,
            patience=10,
            min_epochs=30
        )

        # é˜¶æ®µ3: å¾®è°ƒbackbone
        # éVGGè§£å†»å‰å››å±‚å³å¯
        self.unfreeze_backbone_last_layers(eeg_layers=8, img_layers=8)
        self.unfreeze_heads()
        self.train_stage(
            stage_name="stage3_finetune_backbone",
            lr_head=2e-4,
            lr_backbone=1e-5,
            max_epochs=150,
            patience=10,
            min_epochs=100
        )

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹å’Œè®­ç»ƒå†å²
        self.save_training_history()
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ! æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {self.save_dir}")

        return self.model, self.history

    def save_training_history(self):
        """ä¿å­˜è®­ç»ƒå†å²"""
        # ä¿å­˜å†å²æ•°æ®
        torch.save(self.history, os.path.join(self.save_dir, 'training_history.pth'))

        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self.plot_training_curves()

    def plot_training_curves(self):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        plt.figure(figsize=(20, 15))

        epochs = range(1, len(self.history['all_train_loss']) + 1)

        # æ€»æŸå¤±æ›²çº¿
        plt.subplot(2, 3, 1)
        plt.plot(epochs, self.history['all_train_loss'], label='Train Loss', linewidth=2)
        plt.plot(epochs, self.history['all_val_loss'], label='Val Loss', linewidth=2)
        plt.title('Total Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # å‡†ç¡®ç‡æ›²çº¿
        plt.subplot(2, 3, 2)
        plt.plot(epochs, self.history['all_train_acc'], label='Train Acc', linewidth=2)
        plt.plot(epochs, self.history['all_val_acc'], label='Val Acc', linewidth=2)
        plt.title('Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy (%)')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # ä»»åŠ¡æŸå¤±æ›²çº¿
        plt.subplot(2, 3, 3)
        plt.plot(epochs, self.history['all_task_loss'], label='Task Loss', linewidth=2, color='red')
        plt.title('Task Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # å…±åŒç‰¹å¾ç›¸ä¼¼åº¦æŸå¤±æ›²çº¿
        plt.subplot(2, 3, 4)
        plt.plot(epochs, self.history['all_common_sim_loss'], label='Common Sim Loss', linewidth=2, color='green')
        plt.title('Common Similarity Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # ç§æœ‰ç‰¹å¾å·®å¼‚æŸå¤±æ›²çº¿
        plt.subplot(2, 3, 5)
        plt.plot(epochs, self.history['all_private_diff_loss'], label='Private Diff Loss', linewidth=2, color='purple')
        plt.title('Private Difference Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # æ‰€æœ‰æŸå¤±æ›²çº¿å¯¹æ¯”
        plt.subplot(2, 3, 6)
        plt.plot(epochs, self.history['all_task_loss'], label='Task Loss', linewidth=1)
        plt.plot(epochs, self.history['all_common_sim_loss'], label='Common Sim Loss', linewidth=1)
        plt.plot(epochs, self.history['all_private_diff_loss'], label='Private Diff Loss', linewidth=1)
        plt.title('All Loss Components')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(os.path.join(self.save_dir, 'training_curves.png'), dpi=300, bbox_inches='tight')
        plt.close()


def train_multimodal():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    config = config_multi_model.Config()
    print(f"ä½¿ç”¨è®¾å¤‡: {config.device}")

    trainer = MultiStageTrainer(config)
    trainer.setup_data()
    trainer.setup_model()

    model, history = trainer.train()
    return model, history


if __name__ == "__main__":
    model, history = train_multimodal()